{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T22:53:37.810890Z",
     "iopub.status.busy": "2022-07-04T22:53:37.810583Z",
     "iopub.status.idle": "2022-07-04T22:53:49.830615Z",
     "shell.execute_reply": "2022-07-04T22:53:49.829393Z",
     "shell.execute_reply.started": "2022-07-04T22:53:37.810867Z"
    },
    "id": "WQlSJOuHYIax",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.3.4 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
      "Requirement already satisfied: pandas==1.4.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: seaborn==0.11.2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.11.2)\n",
      "Requirement already satisfied: tensorflow-gpu==2.7.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: cleverhans==4.0.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: pymoo==0.4.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (1.0.2)\n",
      "Requirement already satisfied: tqdm==4.62.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (4.62.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from matplotlib==3.3.4->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from matplotlib==3.3.4->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from matplotlib==3.3.4->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from matplotlib==3.3.4->-r requirements.txt (line 1)) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from matplotlib==3.3.4->-r requirements.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from pandas==1.4.0->-r requirements.txt (line 3)) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from seaborn==0.11.2->-r requirements.txt (line 4)) (1.6.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (14.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.26.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.47.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.9.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: easydict in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (1.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: mnist in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-probability in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: pycodestyle in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (2.8.0)\n",
      "Requirement already satisfied: nose in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from cleverhans==4.0.0->-r requirements.txt (line 6)) (1.3.7)\n",
      "Requirement already satisfied: autograd>=1.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from pymoo==0.4.0->-r requirements.txt (line 7)) (1.4)\n",
      "Requirement already satisfied: cma==2.7 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from pymoo==0.4.0->-r requirements.txt (line 7)) (2.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from scikit-learn==1.0.2->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tqdm==4.62.3->-r requirements.txt (line 9)) (0.4.5)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from autograd>=1.3->pymoo==0.4.0->-r requirements.txt (line 7)) (0.18.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (60.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-probability->cleverhans==4.0.0->-r requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-probability->cleverhans==4.0.0->-r requirements.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from tensorflow-probability->cleverhans==4.0.0->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gf\\pycharmprojects\\pythonproject1\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements.txt (line 5)) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\GF\\PycharmProjects\\pythonProject1\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import uncertainty_wizard as uwiz\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from pymoo.algorithms.nsga2 import NSGA2\n",
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "from pymoo.model.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from plot_keras_history import plot_history\n",
    "import warnings\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T23:26:30.217315Z",
     "iopub.status.busy": "2022-07-04T23:26:30.217030Z",
     "iopub.status.idle": "2022-07-04T23:26:30.221976Z",
     "shell.execute_reply": "2022-07-04T23:26:30.221087Z",
     "shell.execute_reply.started": "2022-07-04T23:26:30.217315Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('data.txt') as f:\n",
    "    data=f.readlines()\n",
    "data[1]=data[1].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "EXPERIMENT_SIZE=int(data[1][0])\n",
    "SAMPLE_SIZE =int(data[1][1])\n",
    "percentage=float(data[1][2])\n",
    "noise_budget =float(data[1][3])\n",
    "T=int(data[1][4])\n",
    "alpha=float(data[1][5])\n",
    "beta=float(data[1][6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 1.0 0.3 40 0.9 0.3\n"
     ]
    }
   ],
   "source": [
    "print(EXPERIMENT_SIZE,SAMPLE_SIZE,percentage,noise_budget,T,alpha,beta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T23:26:31.497770Z",
     "iopub.status.busy": "2022-07-04T23:26:31.497353Z",
     "iopub.status.idle": "2022-07-04T23:26:31.503952Z",
     "shell.execute_reply": "2022-07-04T23:26:31.502606Z",
     "shell.execute_reply.started": "2022-07-04T23:26:31.497770Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 0.3 40 40\n"
     ]
    }
   ],
   "source": [
    "print(alpha,beta,EXPERIMENT_SIZE,T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T23:26:32.378179Z",
     "iopub.status.busy": "2022-07-04T23:26:32.377832Z",
     "iopub.status.idle": "2022-07-04T23:26:32.391243Z",
     "shell.execute_reply": "2022-07-04T23:26:32.389744Z",
     "shell.execute_reply.started": "2022-07-04T23:26:32.378143Z"
    },
    "id": "NaQQiEC2QkGl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class UncertaintyMaximization(Problem):\n",
    "    def __init__(self,input_instance,y, epsilon,beta,alpha):\n",
    "        super().__init__(n_var=X_train.shape[1],\n",
    "                         n_obj=1,\n",
    "                         n_constr=0,\n",
    "                         elementwise_evaluation=True)\n",
    "        self.input_instance = input_instance\n",
    "        self.y = y\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha=alpha\n",
    "        self.beta=beta\n",
    "    def _evaluate(self, noise, out, *args, **kwargs):\n",
    "        prev_results = model.predict_quantified(self.input_instance,\n",
    "                                       quantifier=quantifiers,\n",
    "                                       batch_size=50000,\n",
    "                                       sample_size=T,\n",
    "                                       verbose=0)\n",
    "        \n",
    "        tmp_instance = self.input_instance + noise\n",
    "        results = model.predict_quantified(tmp_instance,\n",
    "                                       quantifier=quantifiers,\n",
    "                                       batch_size=50000,\n",
    "                                       sample_size=T,\n",
    "                                       verbose=0)\n",
    "        unc = results[0][1][0]\n",
    "        y_hat = results[0][0][0]\n",
    "        f1 = self.alpha/(0.0000001 + unc) + 0.01 * np.linalg.norm(noise) + self.beta * (np.int(self.y)==np.int(y_hat))\n",
    "        g1 = np.linalg.norm(noise, ord=np.inf) - self.epsilon\n",
    "        out[\"F\"] = np.column_stack([f1])\n",
    "        out[\"G\"] = np.column_stack([g1])\n",
    "        \n",
    "        #print('U1:', prev_results[0][1][0],'U2:', unc,'Obj:',f1)\n",
    "def get_bounds(uncertainty_budget):\n",
    "    distance = np.max(X_train) - np.min(X_train)\n",
    "    b = (-1*distance*uncertainty_budget/2.0, distance*uncertainty_budget/2.0)\n",
    "\n",
    "    bounds = [b for i in range(X_train.shape[1])]\n",
    "\n",
    "    initial_noise = np.random.uniform(low=np.min(bounds),\n",
    "                                      high=np.max(bounds),\n",
    "                                      size=(X_train.shape[1],))\n",
    "\n",
    "    return bounds,initial_noise\n",
    "def get_model():\n",
    "    model = uwiz.models.StochasticSequential()\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu',input_dim=X_train.shape[1]))\n",
    "    model.add(tf.keras.layers.Dropout(0.09))\n",
    "    model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.09))\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'],run_eagerly=True)\n",
    "    return model\n",
    "def generate_instances(beta,alpha,noise_budget = 0.05, sample_size = 10):#beta=0.1,alpha=0.1):\n",
    "    bounds,initial_noise = get_bounds(noise_budget)\n",
    "    prev_unc_list = []\n",
    "    unc_list = []\n",
    "    prev_pred_list = []\n",
    "    pred_list = []\n",
    "    noise_norm = []\n",
    "    org_x = []\n",
    "    perturbated_x = []\n",
    "    original_y = []\n",
    "    input_norm = []\n",
    "    selected_idx = []\n",
    "    y_tmp_onehot_list = []\n",
    "\n",
    "    for j in tqdm(range(sample_size)):\n",
    "        #i = np.random.randint(0,X_train.shape[0],1)[0]\n",
    "        i=j\n",
    "        #print('i',i)\n",
    "        selected_idx.append(i)\n",
    "        x_tmp = np.array([X_train[i,:],])\n",
    "        y_tmp = y_train[i].argmax()\n",
    "        y_tmp_onehot = y_train[i]\n",
    "\n",
    "        prev_results = model.predict_quantified(x_tmp,\n",
    "                                               quantifier=quantifiers,\n",
    "                                               batch_size=50000,\n",
    "                                               sample_size=30,\n",
    "                                               verbose=0)\n",
    "        problem = UncertaintyMaximization(input_instance=x_tmp,\n",
    "                                          y=y_tmp,\n",
    "                                          epsilon=noise_budget,alpha=alpha,beta=beta)\n",
    "        problem.xl = np.ones((x_tmp.shape[1],)) * np.min(bounds)\n",
    "        problem.xu = np.ones((x_tmp.shape[1],)) * np.max(bounds)\n",
    "\n",
    "        algorithm = NSGA2(\n",
    "                            pop_size=40,\n",
    "                            n_offsprings=10,\n",
    "                            sampling=get_sampling(\"real_random\"),\n",
    "                            crossover=get_crossover(\"real_sbx\", prob=0.9, eta=15),\n",
    "                            mutation=get_mutation(\"real_pm\", eta=20),\n",
    "                            eliminate_duplicates=True\n",
    "                        )\n",
    "\n",
    "        res = minimize(problem,\n",
    "                       algorithm,\n",
    "                       (\"n_gen\", 10),\n",
    "                       verbose=False)\n",
    "\n",
    "        ##############################\n",
    "        ###     Noise generated    ###\n",
    "        ##############################\n",
    "\n",
    "        res1 = model.predict_quantified(x_tmp,\n",
    "                                               quantifier=quantifiers,\n",
    "                                               batch_size=50000,\n",
    "                                               sample_size=T,\n",
    "                                               verbose=0)\n",
    "        x_tmp_noisy = x_tmp + res.X\n",
    "\n",
    "        results = model.predict_quantified(x_tmp_noisy,\n",
    "                                           quantifier=quantifiers,\n",
    "                                           batch_size=50000,\n",
    "                                           sample_size=T,\n",
    "                                           verbose=0)\n",
    "        #print('U1:', res1[0][1][0],'U2:', results[0][1][0])\n",
    "        prev_unc_list.append(prev_results[0][1][0])\n",
    "        prev_pred_list.append(prev_results[0][0][0].astype(int))\n",
    "\n",
    "        unc_list.append(results[0][1][0])\n",
    "        pred_list.append(results[0][0][0].astype(int))\n",
    "\n",
    "        noise_norm.append(np.linalg.norm(res.X))\n",
    "        input_norm.append(np.linalg.norm(x_tmp))\n",
    "        original_y.append(y_tmp)\n",
    "        y_tmp_onehot_list.append(y_tmp_onehot)\n",
    "\n",
    "        org_x.append(x_tmp)\n",
    "        perturbated_x.append(x_tmp_noisy)\n",
    "\n",
    "    df = pd.DataFrame({'idx':selected_idx,'y':original_y,\n",
    "                       'y_hat':prev_pred_list,'y_hat2':pred_list,\n",
    "                       'unc_init':prev_unc_list,'unc_pert':unc_list,\n",
    "                       'input_norm':input_norm,'noise_norm':noise_norm\n",
    "                    })\n",
    "    np.savez(f'train_test_{alpha}_{beta}-' + str(noise_budget) + '.npz',\n",
    "                     X_train=X_train, X_test=X_test, y_train=y_train,\n",
    "                     y_test=y_test, org_x=org_x, perturbated_x=perturbated_x,\n",
    "                     original_y=original_y,prev_pred_list=prev_pred_list,\n",
    "                     pred_list=pred_list,y_tmp_onehot_list=y_tmp_onehot_list)\n",
    "    df.to_csv(f'manipulated_instances_{alpha}_{beta}.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T23:26:34.245731Z",
     "iopub.status.busy": "2022-07-04T23:26:34.245397Z",
     "iopub.status.idle": "2022-07-04T23:26:35.769046Z",
     "shell.execute_reply": "2022-07-04T23:26:35.768122Z",
     "shell.execute_reply.started": "2022-07-04T23:26:34.245703Z"
    },
    "id": "A53rJo6wTEr6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245818\n"
     ]
    }
   ],
   "source": [
    "# demonstrate data normalization with sklearn\n",
    "# load data\n",
    "data = ...\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "infileX = open(\"/datasets/xy/X\",'rb')\n",
    "X = pickle.load(infileX)\n",
    "infiley = open(\"/datasets/xy/y\",'rb')\n",
    "y = pickle.load(infiley)\n",
    "length=int(len(X)*percentage)\n",
    "Xs=X[:length]\n",
    "Ys=y[:length]\n",
    "print(len(Ys))\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, Ys,\n",
    "                                                    test_size=0.33, random_state=27)\n",
    "quantifiers = ['pred_entropy']\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T23:26:43.719291Z",
     "iopub.status.busy": "2022-07-04T23:26:43.719001Z"
    },
    "id": "3a161rZyhfKE",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9037\n",
      "           1       0.00      0.00      0.00      9098\n",
      "           2       0.29      0.00      0.01      8853\n",
      "           3       0.00      0.00      0.00      9062\n",
      "           4       0.00      0.00      0.00      9020\n",
      "           5       0.00      0.00      0.00      9141\n",
      "           6       0.10      0.84      0.18      8909\n",
      "           7       0.00      0.00      0.00      9052\n",
      "           8       0.17      0.12      0.14      8948\n",
      "\n",
      "    accuracy                           0.11     81120\n",
      "   macro avg       0.06      0.11      0.04     81120\n",
      "weighted avg       0.06      0.11      0.04     81120\n",
      "\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc27b3713318451b9f87729d7e464654"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "698352d2d9c94e988a096a6fe68beb90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "314ab7425fe34256bf70f0a665e41316"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c63d4ca6732749ab889a12d745103282"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b50a6c848ae941dd92c6b27a2c9aa53e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c39effe0626b41718909b05ac62966cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f052b4e5150b444ab0092dabcf912450"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8298838a1c244c8e8d367ba0d386af5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3eef66f2ddb46a39357ea5665606dd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "679bc2e2233c43a4a5fee87402c840ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53d8d38ccaa34e2b84a78aa5463918c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Generate instances\n",
    "tf.config.run_functions_eagerly(True)\n",
    "y_hat = model.predict(X_test)\n",
    "cr = classification_report(y_test.argmax(axis=1),y_hat.argmax(axis=1))\n",
    "print(cr)\n",
    "print('*'*50)\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "acc_list = []\n",
    "\n",
    "prec_list.append(precision_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "recall_list.append(recall_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "f1_list.append(f1_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "acc_list.append(accuracy_score(y_test.argmax(axis=1),y_hat.argmax(axis=1)))\n",
    "\n",
    "\n",
    "es_unc = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "model.inner.load_weights('model.hdf5')\n",
    "\n",
    "for _ in range(EXPERIMENT_SIZE):\n",
    "    df = generate_instances(noise_budget = noise_budget, sample_size=T,beta=beta,alpha=alpha)\n",
    "    idx = df.idx.values\n",
    "    if len(idx) > 0:\n",
    "        load_data = np.load(f'train_test_{alpha}_{beta}-' + str(noise_budget) + '.npz')\n",
    "        perturbated_x = load_data['perturbated_x']\n",
    "        original_y = load_data['original_y']\n",
    "        X_train = load_data['X_train']\n",
    "        y_train = load_data['y_train']\n",
    "        X_test = load_data['X_test']\n",
    "        y_test = load_data['y_test']\n",
    "        y_tmp_onehot_list = load_data['y_tmp_onehot_list']\n",
    "\n",
    "        perturbated_x = perturbated_x.reshape((perturbated_x.shape[0],perturbated_x.shape[2]))\n",
    "\n",
    "        new_X_train = np.concatenate((X_train, perturbated_x), axis=0)\n",
    "        new_y_train = np.concatenate((y_train, y_tmp_onehot_list), axis=0)\n",
    "        hist = model.fit(new_X_train, new_y_train, validation_split=0.01,\n",
    "                         batch_size=5000,epochs=10,verbose=0,callbacks=[es_unc])\n",
    "\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "\n",
    "    prec_list.append(precision_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    recall_list.append(recall_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    f1_list.append(f1_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    acc_list.append(accuracy_score(y_test.argmax(axis=1),y_hat.argmax(axis=1)))\n",
    "print(\"beta: \",beta,\"   alpha:  \",alpha)\n",
    "sns.set()\n",
    "f, ax = plt.subplots(1,4, figsize=(12, 2))\n",
    "ax[0].plot(acc_list,label='Accuracy')\n",
    "ax[1].plot(prec_list,label='Precision')\n",
    "ax[2].plot(recall_list,label='Recall')\n",
    "ax[3].plot(f1_list,label='F1')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[2].legend()\n",
    "ax[3].legend()\n",
    "plt.savefig(f'Accuracy_Precision_Recall_{alpha}_{beta}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JL_a9Hnrssix",
    "outputId": "89cc4e74-1bed-4794-e5cb-b9b74cbfad68",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "robust_predictions_train = model.predict_quantified(X_train,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)\n",
    "robust_predictions_test = model.predict_quantified(X_test,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6moXECygWYH",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 2. Adversarial Machine Learning based Test Input Generation\n",
    "\n",
    "adv_model = get_model()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "hist = adv_model.fit(X_train, y_train, validation_split=0.3, batch_size=5000,\n",
    "                     epochs=200, verbose=0, callbacks=[es])\n",
    "\n",
    "init_predictions_train = adv_model.predict_quantified(X_train,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)\n",
    "init_predictions_test = adv_model.predict_quantified(X_test,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)\n",
    "\n",
    "\n",
    "with open('{alpha}_{beta}.pickle', 'wb') as handle:\n",
    "    pickle.dump(hist, handle)\n",
    "plot_history(hist)\n",
    "plt.savefig(f'hist_{alpha}_{beta}.png')\n",
    "adv_model.inner.load_weights('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "axes = ['Init Train', 'After Train','Init Test','After Test']\n",
    "vals = [np.mean(init_predictions_train[0][1]),np.mean(robust_predictions_train[0][1]),\n",
    "        np.mean(init_predictions_test[0][1]),np.mean(robust_predictions_test[0][1]) ]\n",
    "plt.bar(axes,vals)\n",
    "plt.title('Average Uncertainty')\n",
    "plt.savefig(f'Average Uncertainty_{alpha}_{beta}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4M_meG7BghYp",
    "outputId": "a4d14ab6-da23-4661-9003-50aae23ac852",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "norm = np.inf\n",
    "\n",
    "#model.inner.load_weights('model.hdf5')\n",
    "\n",
    "es_adv = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "logits_model = tf.keras.Model(adv_model.inner.input, adv_model.inner.layers[-1].output)\n",
    "\n",
    "y_hat = adv_model.predict(X_test)\n",
    "\n",
    "adv_prec_list = []\n",
    "adv_recall_list = []\n",
    "adv_f1_list = []\n",
    "adv_acc_list = []\n",
    "\n",
    "adv_prec_list.append(precision_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "adv_recall_list.append(recall_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "adv_f1_list.append(f1_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "adv_acc_list.append(accuracy_score(y_test.argmax(axis=1),y_hat.argmax(axis=1)))\n",
    "\n",
    "for i in tqdm(range(EXPERIMENT_SIZE)):\n",
    "    perturbated_x = fast_gradient_method(logits_model, X_train[0:SAMPLE_SIZE,:], noise_budget,\n",
    "                                               norm, targeted=False)\n",
    "\n",
    "    new_X_train = np.concatenate((X_train, perturbated_x), axis=0)\n",
    "    new_y_train = np.concatenate((y_train, y_train[0:SAMPLE_SIZE]), axis=0)\n",
    "\n",
    "    model.inner.load_weights('model.hdf5')\n",
    "    \n",
    "    hist = adv_model.fit(new_X_train, new_y_train, validation_split=0.3,\n",
    "                         batch_size=5000,epochs=5,verbose=0,callbacks=[es_adv])\n",
    "    \n",
    "    y_hat = adv_model.predict(X_test)\n",
    "        \n",
    "    adv_prec_list.append(precision_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    adv_recall_list.append(recall_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    adv_f1_list.append(f1_score(y_test.argmax(axis=1),y_hat.argmax(axis=1),average='weighted'))\n",
    "    adv_acc_list.append(accuracy_score(y_test.argmax(axis=1),y_hat.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "huVazWB4gmtU",
    "outputId": "c9ba0fcd-6616-4d0a-ceb4-12e07dae9bd5",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "f, ax = plt.subplots(1,4, figsize=(12, 2))\n",
    "ax[0].plot(adv_acc_list,label='Accuracy')\n",
    "ax[1].plot(adv_prec_list,label='Precision')\n",
    "ax[2].plot(adv_recall_list,label='Recall')\n",
    "ax[3].plot(adv_f1_list,label='F1')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[2].legend()\n",
    "ax[3].legend()\n",
    "plt.savefig(f'Accuracy_Precision_Recall_2{alpha}_{beta}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ID4WP0R7gn5D",
    "outputId": "cdbff17f-4cde-45d3-aa64-63a645234e28",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "adv_robust_predictions_train = adv_model.predict_quantified(X_train,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)\n",
    "adv_robust_predictions_test = adv_model.predict_quantified(X_test,\n",
    "                                                   quantifier=quantifiers,\n",
    "                                                   batch_size=50000,\n",
    "                                                   sample_size=T,\n",
    "                                                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "axes = ['Init Train', 'After Train','Init Test','After Test']\n",
    "vals = [np.mean(init_predictions_train[0][1]),np.mean(adv_robust_predictions_train[0][1]),\n",
    "        np.mean(init_predictions_test[0][1]),np.mean(adv_robust_predictions_test[0][1]) ]\n",
    "plt.bar(axes,vals)\n",
    "plt.title('Average Uncertainty')\n",
    "plt.savefig(f'Average Uncertainty_2{alpha}_{beta}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dill.dump_session(f'notebook_env{alpha}_{beta}.db')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}